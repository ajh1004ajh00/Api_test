{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c400862-e42c-4e3b-ab22-9c846a55d914",
   "metadata": {},
   "source": [
    "## Model I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf69c55-0e81-4a23-9f75-a44c62cbc4f4",
   "metadata": {},
   "source": [
    "### Message\n",
    "\n",
    "기본 메시지 인터페이스는 BaseMessage에 의해 정의되며, 두 가지 필수 속성이 있습니다\n",
    "\n",
    "- content: 메시지의 내용입니다. 보통 문자열입니다.\n",
    "- role: BaseMessage가 오는 엔티티입니다.\n",
    "\n",
    "\n",
    "LangChain은 다양한 역할을 쉽게 구분할 수 있는 여러 객체를 제공합니다:\n",
    "\n",
    "- HumanMessage: 사용자/인간으로부터 오는 BaseMessage입니다.\n",
    "- AIMessage: AI/어시스턴트로부터 오는 BaseMessage입니다.\n",
    "- SystemMessage: 시스템으로부터 오는 BaseMessage입니다.\n",
    "- 이들 역할 중 어느 것도 적절하지 않다면, `role`을 수동으로 지정할 수 있는 ChatMessage 클래스도 있습니다.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "chat_model.invoke(messages)\n",
    "# >> AIMessage(content=\"Socks O'Color\")\n",
    "```\n",
    "\n",
    "ChatModel.invoke를 수행하면 `Message의 리스트`를 입력으로 받고 `Message`를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e0f11f-3b4d-4ccf-900c-918b1715fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05010a5-f074-47b8-80c3-3a7f2cde6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918eacd6-8f26-4ee4-a438-3df878546491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-727e9251-84ec-46b2-ae19-6464315a2cc5-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"안녕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc436f5-f96e-4116-b732-44f99f06dc20",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b886a98-e907-40be-bf65-7786e4931e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712fc4b4-0ed4-4ba9-99ec-63f20bc90d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 시작\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 AI 번역 모델이다.\"),\n",
    "    HumanMessage(content=\"'안녕' 이 문장이 영어로 뭐야?\"),\n",
    "]\n",
    "\n",
    "# 챗 모델을 호출하여 응답을 받습니다.\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5928c26b-b056-416f-92ae-6d0a75cb5491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"'안녕'은 영어로 'hello'이다.\", response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 42, 'total_tokens': 59}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-11e4d53b-a6f0-470e-890c-e0eaddbb8077-0', usage_metadata={'input_tokens': 42, 'output_tokens': 17, 'total_tokens': 59})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f490ef2-1a60-446d-97df-8d9c26a328a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'안녕'은 영어로 'hello'이다.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa52e0-99c3-4d92-b175-6ce06f95c5bd",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4db5c-d360-4121-850d-e8211805032c",
   "metadata": {},
   "source": [
    "Prompt template과 LLM 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75e3e5e-b8e5-46bb-b184-e3bbbeed85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea047ece-4436-4f1e-9d1b-927b6f7fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 template\n",
    "human_message_prompt = \"'{text}' 여기서 키워드를 뽑아서 콤마로 구분해줘\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_prompt)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a897e4-17f0-4a69-a552-a9f4ff9518e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4267d4ba-0447-4919-a1f5-30cb301c0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain.invoke({\"text\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16281632-8245-492b-8a6a-c9d6afe54eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain, framework, developing applications, language models', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 46, 'total_tokens': 56}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4ec7d332-67c8-4a42-93a4-ab704ac03cc6-0', usage_metadata={'input_tokens': 46, 'output_tokens': 10, 'total_tokens': 56})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d994c502-974e-4126-ab8e-d3b91146254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain, framework, developing applications, language models'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6e372-daf4-4c95-88e8-e99cf45a93db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
