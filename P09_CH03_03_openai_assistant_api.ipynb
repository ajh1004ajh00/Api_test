{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API ì‚¬ìš© ë°©ë²• ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒˆë¡œìš´ [Assistants API](https://platform.openai.com/docs/assistants/overview)ëŠ” [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)ì˜ ë°œì „ëœ í˜•íƒœë¡œ, ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ assistantë¥¼ ë§Œë“¤ê³ , ê°œë°œìê°€ Code Interpreter ë° Retrievalê³¼ ê°™ì€ ê°•ë ¥í•œ ë„êµ¬ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants API Diagram](images/assistants_overview_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API vs Assistants API\n",
    "\n",
    "**Chat Completions API**ì˜ ê¸°ë³¸ ë‹¨ìœ„ëŠ” `Messages`ì´ë©°, ì—¬ê¸°ì— `Model`(`gpt-3.5-turbo`, `gpt-4` ë“±)ì„ ì‚¬ìš©í•˜ì—¬ `Completion`ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ APIëŠ” ê°€ë³ê³  ê°•ë ¥í•˜ì§€ë§Œ ë³¸ì§ˆì ìœ¼ë¡œ ìƒíƒœê°€ ì—†ê¸° ë•Œë¬¸ì— ëŒ€í™” ìƒíƒœ, ë„êµ¬ ì •ì˜, ê²€ìƒ‰ ë¬¸ì„œ, ì½”ë“œ ì‹¤í–‰ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**Assistants API**ì˜ ê¸°ë³¸ ë‹¨ìœ„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ê¸°ë³¸ ëª¨ë¸, ì§€ì¹¨, ë„êµ¬, ë¬¸ì„œ(ë¬¸ë§¥)ë¥¼ í¬í•¨í•˜ëŠ” `Assistants`,\n",
    "- ëŒ€í™”ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” `Threads`,\n",
    "- í…ìŠ¤íŠ¸ ì‘ë‹µ ë° ë‹¤ë‹¨ê³„ ë„êµ¬ ì‚¬ìš©ì„ í¬í•¨í•˜ì—¬ `Thread`ì—ì„œ `Assistant`ì˜ ì‹¤í–‰ì„ êµ¬ë™í•˜ëŠ” `Runs`.\n",
    "\n",
    "ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ê°•ë ¥í•˜ê³  ìƒíƒœê°€ ìˆëŠ” ê²½í—˜ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajhaj\\anaconda3\\envs\\link_dl\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 1.51.2\n"
     ]
    }
   ],
   "source": [
    "!pip show openai | findstr Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty Printing Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example with Assistants API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistants APIë¥¼ ì‹œì‘í•˜ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•ì€ [Assistants Playground](https://platform.openai.com/playground)ë¥¼ í†µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants Playground](images/assistants_overview_assistants_playground.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assistantë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤! [ë¬¸ì„œ](https://platform.openai.com/docs/assistants/overview)ì— ìˆëŠ” ê²ƒì²˜ëŸ¼ ìˆ˜í•™ ê³¼ì™¸ ì„ ìƒë‹˜ì„ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creating New Assistant](images/assistants_overview_new_assistant.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ assistantë“¤ì€ [Assistants Dashboard](https://platform.openai.com/assistants)ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants Dashboard](images/assistants_overview_assistants_dashboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ ë‹¤ìŒê³¼ ê°™ì´ Assistants APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ Assistantë¥¼ ìƒì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_NumaNLIgmpjeAKo16jh0PKPJ',\n",
       " 'created_at': 1728579022,\n",
       " 'description': None,\n",
       " 'instructions': 'ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': None, 'file_search': None},\n",
       " 'top_p': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ Assistantë¥¼ ìƒì„±í•˜ë“  APIë¥¼ ì‚¬ìš©í•˜ë“ , Assistant IDë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ IDë¥¼ í†µí•´ Threadsì™€ Runs ì „ë°˜ì— ê±¸ì³ Assistantë¥¼ ì°¸ì¡°í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, ìƒˆë¡œìš´ Threadë¥¼ ìƒì„±í•˜ê³  ê·¸ ì•ˆì— Messageë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëŒ€í™”ì˜ ìƒíƒœë¥¼ ìœ ì§€í•  ìˆ˜ ìˆì–´, ë§¤ë²ˆ ì „ì²´ ë©”ì‹œì§€ ê¸°ë¡ì„ ë‹¤ì‹œ ë³´ë‚¼ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒˆë¡œìš´ Thread ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn',\n",
       " 'created_at': 1728575837,\n",
       " 'metadata': {},\n",
       " 'object': 'thread',\n",
       " 'tool_resources': {'code_interpreter': None, 'file_search': None}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threadì— message ì¶”ê°€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_0EPqVBvffWMtB3DVzfsjJJVe',\n",
       " 'assistant_id': None,\n",
       " 'attachments': [],\n",
       " 'completed_at': None,\n",
       " 'content': [{'text': {'annotations': [], 'value': \"ë°©ì •ì‹ '3x + 11 = 14'ë¥¼ í’€ì–´ì¤˜\"},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1728575854,\n",
       " 'incomplete_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'status': None,\n",
       " 'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"ë°©ì •ì‹ '3x + 11 = 14'ë¥¼ í’€ì–´ì¤˜\"\n",
    ")\n",
    "show_json(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> ë§¤ë²ˆ ì „ì²´ ê¸°ë¡ì„ ë³´ë‚´ì§€ ì•Šë”ë¼ë„, ê° Runë§ˆë‹¤ ì „ì²´ ëŒ€í™” ê¸°ë¡ì˜ í† í°ì— ëŒ€í•´ ìš”ê¸ˆì´ ì²­êµ¬ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs\n",
    "\n",
    "ìš°ë¦¬ê°€ ë§Œë“  Threadê°€ ì•ì„œ ë§Œë“  Assistantì™€ **ì—°ê²°ë˜ì§€ ì•Šì•˜ìŒ**ì„ ì£¼ëª©í•˜ì„¸ìš”! ThreadëŠ” Assistantsì™€ ë…ë¦½ì ìœ¼ë¡œ ì¡´ì¬í•˜ë©°, ì´ëŠ” ChatGPT(ëª¨ë¸/GPTì— threadê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”)ë¥¼ ì‚¬ìš©í•´ ë³¸ ì‚¬ëŒë“¤ì´ ì˜ˆìƒí•˜ëŠ” ê²ƒê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ì–´ì§„ Threadì— ëŒ€í•œ Assistantì˜ Completionì„ ì–»ìœ¼ë ¤ë©´ Runì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. Runì„ ìƒì„±í•˜ë©´ Assistantì—ê²Œ Threadì˜ ë©”ì‹œì§€ë¥¼ ì‚´í´ë³´ê³  ì¡°ì¹˜ë¥¼ ì·¨í•˜ë¼ëŠ” ì§€ì‹œê°€ ë©ë‹ˆë‹¤. ë‹¨ì¼ ì‘ë‹µì„ ì¶”ê°€í•˜ê±°ë‚˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> **ì°¸ê³ **\n",
    "> RunsëŠ” Assistants APIì™€ Chat Completions API ì‚¬ì´ì˜ ì£¼ìš” ì°¨ì´ì ì…ë‹ˆë‹¤. Chat Completionsì—ì„œëŠ” ëª¨ë¸ì´ ë‹¨ì¼ ë©”ì‹œì§€ë¡œë§Œ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ë°˜ë©´, Assistants APIì—ì„œëŠ” Runì„ í†µí•´ Assistantê°€ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  Threadì— ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ Assistantì—ê²Œ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•˜ë„ë¡ í•˜ë ¤ë©´ Runì„ ìƒì„±í•©ì‹œë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´, Assistantì™€ Threadë¥¼ _ëª¨ë‘_ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_HR1zNgIixNM3T3h7MX4QRm3a',\n",
       " 'assistant_id': 'asst_dL7GXryfiTzV7zAQ1rvE72xI',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1728575887,\n",
       " 'expires_at': 1728576487,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': 'ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜',\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'object': 'thread.run',\n",
       " 'parallel_tool_calls': True,\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'usage': None,\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completions APIì—ì„œ ì™„ì„±ì„ ìƒì„±í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, **Runì„ ìƒì„±í•˜ëŠ” ê²ƒì€ ë¹„ë™ê¸° ì‘ì—…ì…ë‹ˆë‹¤**. ì´ ì‘ì—…ì€ Runì˜ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì¦‰ì‹œ ë°˜í™˜ë˜ë©°, ì—¬ê¸°ì—ëŠ” ì²˜ìŒì— `queued`ë¡œ ì„¤ì •ëœ `status`ê°€ í¬í•¨ë©ë‹ˆë‹¤. Assistantê°€ ë„êµ¬ ì‚¬ìš©ê³¼ ë©”ì‹œì§€ ì¶”ê°€ì™€ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•¨ì— ë”°ë¼ `status`ê°€ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n",
    "\n",
    "Assistantê°€ ì²˜ë¦¬ë¥¼ ì™„ë£Œí–ˆëŠ”ì§€ ì•Œê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Runì„ ë°˜ë³µì ìœ¼ë¡œ í´ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›ì´ ê³§ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤!) ì—¬ê¸°ì„œëŠ” `queued` ë˜ëŠ” `in_progress` ìƒíƒœë§Œ í™•ì¸í•˜ì§€ë§Œ, ì‹¤ì œë¡œ Runì€ ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” [ë‹¤ì–‘í•œ ìƒíƒœ ë³€ê²½](https://platform.openai.com/docs/api-reference/runs/object#runs/object-status)ì„ ê²ªì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì´ê²ƒë“¤ì„ Stepsë¼ê³  í•˜ë©° ë‚˜ì¤‘ì— ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_HR1zNgIixNM3T3h7MX4QRm3a',\n",
       " 'assistant_id': 'asst_dL7GXryfiTzV7zAQ1rvE72xI',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1728575888,\n",
       " 'created_at': 1728575887,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': 'ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜',\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'object': 'thread.run',\n",
       " 'parallel_tool_calls': True,\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': 1728575887,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'usage': {'completion_tokens': 8, 'prompt_tokens': 68, 'total_tokens': 76},\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ, Assistantê°€ ë¬´ì—‡ì„ ì¶”ê°€í–ˆëŠ”ì§€ ë³´ê¸° ìœ„í•´ Thread ì•ˆì˜ ë©”ì‹œì§€ë“¤ì„ ë‚˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_OdqrGcLYVjuoot4pvQvPjJrd',\n",
       "   'assistant_id': 'asst_dL7GXryfiTzV7zAQ1rvE72xI',\n",
       "   'attachments': [],\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [], 'value': 'x = 1ì…ë‹ˆë‹¤.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1728575888,\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_HR1zNgIixNM3T3h7MX4QRm3a',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn'},\n",
       "  {'id': 'msg_0EPqVBvffWMtB3DVzfsjJJVe',\n",
       "   'assistant_id': None,\n",
       "   'attachments': [],\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': \"ë°©ì •ì‹ '3x + 11 = 14'ë¥¼ í’€ì–´ì¤˜\"},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1728575854,\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_OdqrGcLYVjuoot4pvQvPjJrd',\n",
       " 'last_id': 'msg_0EPqVBvffWMtB3DVzfsjJJVe',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë³´ì‹œë‹¤ì‹œí”¼ ë©”ì‹œì§€ë“¤ì€ ì—­ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤ - ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ê°€ì¥ ìµœê·¼ì˜ ê²°ê³¼ê°€ í•­ìƒ ì²« ë²ˆì§¸ 'í˜ì´ì§€'ì— ìˆê²Œ ë©ë‹ˆë‹¤(ê²°ê³¼ëŠ” í˜ì´ì§€ë„¤ì´ì…˜ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ). ì´ëŠ” Chat Completions APIì˜ ë©”ì‹œì§€ ìˆœì„œì™€ ë°˜ëŒ€ì´ë¯€ë¡œ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ì˜ Assistantì—ê²Œ ê²°ê³¼ì— ëŒ€í•´ ì¢€ ë” ì„¤ëª…í•´ë‹¬ë¼ê³  ìš”ì²­í•´ ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_nyfGN41q9uKdYRFUeEQNjHYY',\n",
       "   'assistant_id': 'asst_dL7GXryfiTzV7zAQ1rvE72xI',\n",
       "   'attachments': [],\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'ì–‘ë³€ì—ì„œ 11ì„ ë¹¼ë©´, \\\\(3x = 3\\\\). ì–‘ë³€ì„ 3ìœ¼ë¡œ ë‚˜ëˆ„ë©´, \\\\(x = 1\\\\)ì…ë‹ˆë‹¤.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1728576011,\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_mrL2uhgGRdtfoJF7vVSwehu8',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_KfZbQYNHHNcLc0lazOirJ3zn'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_nyfGN41q9uKdYRFUeEQNjHYY',\n",
       " 'last_id': 'msg_nyfGN41q9uKdYRFUeEQNjHYY',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a message to append to our thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    ")\n",
    "\n",
    "# Execute our run\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# Wait for completion\n",
    "wait_on_run(run, thread)\n",
    "\n",
    "# Retrieve all the messages added after our last user message\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, order=\"asc\", after=message.id\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ê²ƒì´ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ìœ„í•´ ì‘ë‹µì„ ë°›ê¸°ê¹Œì§€ ë§ì€ ë‹¨ê³„ê°€ í•„ìš”í•œ ê²ƒì²˜ëŸ¼ ëŠê»´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ìš°ë¦¬ëŠ” ì½”ë“œë¥¼ ê±°ì˜ ë³€ê²½í•˜ì§€ ì•Šê³ ë„ ìš°ë¦¬ì˜ Assistantì— ë§¤ìš° ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ê³§ ë³´ê²Œ ë  ê²ƒì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ëª¨ë“  ê²ƒì„ ì–´ë–»ê²Œ ê²°í•©í•  ìˆ˜ ìˆëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ìƒì„±í•œ Assistantë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ê°€ ì´ë¯¸ ìˆ˜í•™ Assistantë¥¼ ë§Œë“¤ì—ˆê¸° ë•Œë¬¸ì—, ê·¸ IDë¥¼ `MATH_ASSISTANT_ID`ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë‘ ê°œì˜ í•¨ìˆ˜ë¥¼ ì •ì˜í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- `submit_message`: Threadì— Messageë¥¼ ìƒì„±í•œ ë‹¤ìŒ, ìƒˆë¡œìš´ Runì„ ì‹œì‘í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- `get_response`: Threadì˜ ë©”ì‹œì§€ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "MATH_ASSISTANT_ID = assistant.id  # or a hard-coded ID like \"asst-...\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=user_message\n",
    "    )\n",
    "    return client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_response(thread):\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” `create_thread_and_run` í•¨ìˆ˜ë¥¼ ì •ì˜í–ˆëŠ”ë°, ì´ëŠ” ì‹¤ì œë¡œ ìš°ë¦¬ APIì˜ [`client.beta.threads.create_and_run`](https://platform.openai.com/docs/api-reference/runs/createThreadAndRun) ë³µí•© í•¨ìˆ˜ì™€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê°ê°ì˜ ê°€ìƒ ì‚¬ìš©ì ìš”ì²­ì„ ìƒˆë¡œìš´ Threadì— ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë“  API í˜¸ì¶œì€ ë¹„ë™ê¸° ì‘ì—…ì´ë¼ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”; ì´ëŠ” ìš°ë¦¬ê°€ `asyncio`ì™€ ê°™ì€ ë¹„ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì‚¬ìš© ì—†ì´ë„ ì‹¤ì œë¡œ ì½”ë“œì—ì„œ ë¹„ë™ê¸° ë™ì‘ì„ ì–»ì„ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_and_run(user_input):\n",
    "    thread = client.beta.threads.create()\n",
    "    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)\n",
    "    return thread, run\n",
    "\n",
    "\n",
    "# Emulating concurrent user requests\n",
    "thread1, run1 = create_thread_and_run(\n",
    "    \"ë°©ì •ì‹ '3x + 11 = 14'ë¥¼ í’€ì–´ì¤˜\"\n",
    ")\n",
    "thread2, run2 = create_thread_and_run(\"ì„ í˜•ëŒ€ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\") # ë™ê¸°ì ì´ë¼ë©´ ìœ„ì—êº¼ê°€ ì™„ë£Œë˜ê¸° ì „ê¹Œì§€ ì´ ì½”ë“œ ì‘ë™ x\n",
    "thread3, run3 = create_thread_and_run(\"ë‚˜ëŠ” ìˆ˜í•™ì„ ì‹«ì–´í•´. ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?\")\n",
    "\n",
    "# Now all Runs are executing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  Runì´ ì§„í–‰ë˜ê³  ë‚˜ë©´, ê°ê°ì„ ê¸°ë‹¤ë¦° í›„ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: ë°©ì •ì‹ '3x + 11 = 14'ë¥¼ í’€ì–´ì¤˜\n",
      "assistant: x = 1.\n",
      "\n",
      "# Messages\n",
      "user: ì„ í˜•ëŒ€ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "assistant: ì„ í˜•ëŒ€ìˆ˜ëŠ” ë²¡í„° ê³µê°„ê³¼ ì„ í˜• ë³€í™˜ì„ ì—°êµ¬í•˜ëŠ” ìˆ˜í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "# Messages\n",
      "user: ë‚˜ëŠ” ìˆ˜í•™ì„ ì‹«ì–´í•´. ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?\n",
      "assistant: ì‹¤ìš©ì ì¸ ëª©ì ì´ë‚˜ ì¬ë¯¸ìˆëŠ” ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”.\n",
      "\n",
      "# Messages\n",
      "user: ë‚˜ëŠ” ìˆ˜í•™ì„ ì‹«ì–´í•´. ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?\n",
      "assistant: ì‹¤ìš©ì ì¸ ëª©ì ì´ë‚˜ ì¬ë¯¸ìˆëŠ” ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì„¸ìš”.\n",
      "user: ê³ ë§ˆì›Œ\n",
      "assistant: ì²œë§Œì—!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Pretty printing helper\n",
    "def pretty_print(messages):\n",
    "    print(\"# Messages\")\n",
    "    for m in messages:\n",
    "        print(f\"{m.role}: {m.content[0].text.value}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Waiting in a loop\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "\n",
    "# Wait for Run 1 # ë¹„ë™ê¸°ì ì´ë¼ ëª¨ë“  ìš”ì²­ë“¤ì´ í•œë²ˆì— ëë‚¼ ìˆ˜ ìˆìŒ\n",
    "run1 = wait_on_run(run1, thread1)\n",
    "pretty_print(get_response(thread1))\n",
    "\n",
    "# Wait for Run 2\n",
    "run2 = wait_on_run(run2, thread2)\n",
    "pretty_print(get_response(thread2))\n",
    "\n",
    "# Wait for Run 3\n",
    "run3 = wait_on_run(run3, thread3)\n",
    "pretty_print(get_response(thread3))\n",
    "\n",
    "# Thank our assistant on Thread 3 :)\n",
    "run4 = submit_message(MATH_ASSISTANT_ID, thread3, \"ê³ ë§ˆì›Œ\")\n",
    "run4 = wait_on_run(run4, thread3)\n",
    "pretty_print(get_response(thread3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëë‚¬ìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì—¬ëŸ¬ë¶„ì€ ì´ ì½”ë“œê°€ ì‹¤ì œë¡œëŠ” ìš°ë¦¬ì˜ ìˆ˜í•™ Assistantì— íŠ¹í™”ë˜ì–´ ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ëˆˆì¹˜ì±˜ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤... Assistant IDë¥¼ ë³€ê²½í•˜ê¸°ë§Œ í•˜ë©´ ì–´ë–¤ ìƒˆë¡œìš´ Assistantì— ëŒ€í•´ì„œë„ ì´ ì½”ë“œê°€ ì‘ë™í•©ë‹ˆë‹¤! ì´ê²ƒì´ Assistants APIì˜ í˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Assistants APIì˜ í•µì‹¬ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” Code Interpreter, Retrieval ë° ì‚¬ìš©ì ì •ì˜ Functionsê³¼ ê°™ì€ ë„êµ¬ë¥¼ ìš°ë¦¬ì˜ Assistantsì— ì¥ì°©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤. ê°ê°ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### Code Interpreter\n",
    "\n",
    "ìš°ë¦¬ì˜ ìˆ˜í•™ ê³¼ì™¸ ì„ ìƒë‹˜ì—ê²Œ [Code Interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter) ë„êµ¬ë¥¼ ì¥ì°©í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì€ ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enabling code interpreter](images/assistants_overview_enable_code_interpreter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...ë˜ëŠ” Assistant IDë¥¼ ì‚¬ìš©í•˜ì—¬ APIë¥¼ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_dL7GXryfiTzV7zAQ1rvE72xI',\n",
       " 'created_at': 1728575057,\n",
       " 'description': None,\n",
       " 'instructions': 'ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}],\n",
       " 'response_format': {'type': 'text'},\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': {'file_ids': []}, 'file_search': None},\n",
       " 'top_p': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ Assistantì—ê²Œ ìƒˆ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìš”ì²­í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒ 10ê°œì˜ í”¼ë³´ë‚˜ì¹˜ ìˆ«ìë¥¼ ìƒì„±í•´ì¤˜\n",
      "assistant: ì²˜ìŒ 10ê°œì˜ í”¼ë³´ë‚˜ì¹˜ ìˆ«ìëŠ” [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]ì…ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒ 10ê°œì˜ í”¼ë³´ë‚˜ì¹˜ ìˆ«ìë¥¼ ìƒì„±í•´ì¤˜\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë¦¬ê³  ëë‚¬ìŠµë‹ˆë‹¤! AssistantëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ Code Interpreterë¥¼ ì‚¬ìš©í–ˆê³ , ìµœì¢… ì‘ë‹µì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì¼ë¶€ ì‚¬ìš© ì‚¬ë¡€ì—ì„œëŠ” ì´ ì •ë„ë©´ ì¶©ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ Assistantê°€ ì •í™•íˆ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ë” ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´ Runì˜ Stepsë¥¼ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runì€ í•˜ë‚˜ ì´ìƒì˜ Stepsë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. Runê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ê° Stepì—ëŠ” ì¡°íšŒí•  ìˆ˜ ìˆëŠ” `status`ê°€ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì—ê²Œ Stepì˜ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤(ì˜ˆ: Assistantê°€ ì½”ë“œë¥¼ ì‘ì„±í•˜ê±°ë‚˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë™ì•ˆ ìŠ¤í”¼ë„ˆ í‘œì‹œ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id, run_id=run.id, order=\"asc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê° Stepì˜ `step_details`ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_calls': [{'id': 'call_l5e6dtjYHCBBayqxKcK2a6Oq',\n",
       "   'code_interpreter': {'input': 'def fibonacci_sequence(n):\\n    fib_sequence = [0, 1]\\n    while len(fib_sequence) < n:\\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n    return fib_sequence\\n\\nfirst_10_fibonacci = fibonacci_sequence(10)\\nfirst_10_fibonacci',\n",
       "    'outputs': []},\n",
       "   'type': 'code_interpreter'}],\n",
       " 'type': 'tool_calls'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message_creation': {'message_id': 'msg_vcwfkjbn2wTs5ZvfMBqQ6sB6'},\n",
       " 'type': 'message_creation'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data:\n",
    "    step_details = step.step_details\n",
    "    print(json.dumps(show_json(step_details), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‘ Stepì˜ `step_details`ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. `tool_calls` (í•˜ë‚˜ì˜ Stepì— í•˜ë‚˜ ì´ìƒì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³µìˆ˜í˜•)\n",
    "2. `message_creation`\n",
    "\n",
    "ì²« ë²ˆì§¸ Stepì€ `tool_calls`ë¡œ, íŠ¹íˆ `code_interpreter`ë¥¼ ì‚¬ìš©í•˜ëŠ”ë° ì—¬ê¸°ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:\n",
    "\n",
    "- ë„êµ¬ê°€ í˜¸ì¶œë˜ê¸° ì „ì— ìƒì„±ëœ Python ì½”ë“œì¸ `input`, ê·¸ë¦¬ê³ \n",
    "- Code Interpreterë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ì¸ `output`.\n",
    "\n",
    "ë‘ ë²ˆì§¸ Stepì€ `message_creation`ìœ¼ë¡œ, ì‚¬ìš©ìì—ê²Œ ê²°ê³¼ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•´ Threadì— ì¶”ê°€ëœ `message`ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file search\n",
    "\n",
    "Assistants APIì˜ ë˜ ë‹¤ë¥¸ ê°•ë ¥í•œ ë„êµ¬ëŠ” [file search](https://platform.openai.com/docs/assistants/tools/file-search/quickstart)ì…ë‹ˆë‹¤: ì§ˆë¬¸ì— ë‹µí•  ë•Œ assistantê°€ ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ë„ ëŒ€ì‹œë³´ë“œ ë˜ëŠ” APIì—ì„œ í™œì„±í™”í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name=\"machine learning\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"data/language_models_are_unsupervised_multitask_learners.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams)\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_kapTM3MdsjHAguqiTCXjX3Xy',\n",
       " 'created_at': 1716706179,\n",
       " 'description': None,\n",
       " 'instructions': 'ë„ˆëŠ” ê°œì¸ ìˆ˜í•™ êµì‚¬ì•¼. ì§ˆë¬¸ì— í•œ ë¬¸ì¥ ì´í•˜ë¡œ ì§§ê²Œ ë‹µí•´ì¤˜',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}, {'type': 'file_search'}],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': {'file_ids': []},\n",
       "  'file_search': {'vector_store_ids': ['vs_npS5ZqeENO4FeKrEGTepl6eJ']}},\n",
       " 'top_p': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update Assistant\n",
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: ì´ ë…¼ë¬¸ì˜ ë°°ê²½ì´ ë˜ëŠ” ìˆ˜í•™ ê°œë…ì€ ë­ì•¼? ë‘ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\n",
      "assistant: ì´ ë…¼ë¬¸ì˜ ë°°ê²½ì´ ë˜ëŠ” ìˆ˜í•™ ê°œë…ì€ í™•ë¥ ì  ëª¨ë¸ë§ê³¼ ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ(multitask learning)ì…ë‹ˆë‹¤ã€4:0â€ sourceã€‘.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"ì´ ë…¼ë¬¸ì˜ ë°°ê²½ì´ ë˜ëŠ” ìˆ˜í•™ ê°œë…ì€ ë­ì•¼? ë‘ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> Retrievalì—ëŠ” [Annotations](https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages)ì™€ ê°™ì€ ë” ë³µì¡í•œ ê¸°ëŠ¥ë“¤ì´ ìˆìœ¼ë©°, ì´ëŠ” ë‹¤ë¥¸ ì¿¡ë¶ì—ì„œ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_response_from_user_multiple_choice():\n",
    "    return \"a\"\n",
    "\n",
    "\n",
    "def get_mock_response_from_user_free_response():\n",
    "    return \"I don't know.\"\n",
    "\n",
    "\n",
    "def display_quiz(title, questions):\n",
    "    print(\"Quiz:\", title)\n",
    "    print()\n",
    "    responses = []\n",
    "\n",
    "    for q in questions:\n",
    "        print(q[\"question_text\"])\n",
    "        response = \"\"\n",
    "\n",
    "        # If multiple choice, print options\n",
    "        if q[\"question_type\"] == \"MULTIPLE_CHOICE\":\n",
    "            for i, choice in enumerate(q[\"choices\"]):\n",
    "                print(f\"{i}. {choice}\")\n",
    "            response = get_mock_response_from_user_multiple_choice()\n",
    "\n",
    "        # Otherwise, just get response\n",
    "        elif q[\"question_type\"] == \"FREE_RESPONSE\":\n",
    "            response = get_mock_response_from_user_free_response()\n",
    "\n",
    "        responses.append(response)\n",
    "        print()\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ ìƒ˜í”Œ í€´ì¦ˆê°€ ì–´ë–»ê²Œ ë³´ì¼ì§€ì— ëŒ€í•œ ì˜ˆì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = display_quiz(\n",
    "    \"Sample Quiz\",\n",
    "    [\n",
    "        {\"question_text\": \"ì´ë¦„ì´ ë­ì•¼?\", \"question_type\": \"FREE_RESPONSE\"},\n",
    "        {\n",
    "            \"question_text\": \"ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìƒ‰ì´ ë­ì•¼?\",\n",
    "            \"question_type\": \"MULTIPLE_CHOICE\",\n",
    "            \"choices\": [\"ë¹¨ê°„ìƒ‰\", \"íŒŒë‘ìƒ‰\", \"ì´ˆë¡ìƒ‰\", \"ë…¸ë€ìƒ‰\"],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Responses:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ, Assistantê°€ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì´ í•¨ìˆ˜ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì •ì˜í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_json = {\n",
    "    \"name\": \"display_quiz\",\n",
    "    \"description\": \"í•™ìƒì—ê²Œ í€´ì¦ˆë¥¼ í‘œì‹œí•˜ê³  í•™ìƒì˜ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤. í•˜ë‚˜ì˜ í€´ì¦ˆì— ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"questions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"ì œëª©ê³¼ ì˜µì…˜(ê°ê´€ì‹ì¸ ê²½ìš°)ì´ ìˆëŠ” ì§ˆë¬¸ì˜ ë°°ì—´ì…ë‹ˆë‹¤.\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question_text\": {\"type\": \"string\"},\n",
    "                        \"question_type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"MULTIPLE_CHOICE\", \"FREE_RESPONSE\"],\n",
    "                        },\n",
    "                        \"choices\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                    },\n",
    "                    \"required\": [\"question_text\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"title\", \"questions\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ì‹œ í•œë²ˆ, ëŒ€ì‹œë³´ë“œë‚˜ APIë¥¼ í†µí•´ ìš°ë¦¬ì˜ Assistantë¥¼ ì—…ë°ì´íŠ¸í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enabling custom function](images/assistants_overview_enable_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[\n",
    "        {\"type\": \"code_interpreter\"},\n",
    "        {\"type\": \"retrieval\"},\n",
    "        {\"type\": \"function\", \"function\": function_json},\n",
    "    ],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ í€´ì¦ˆë¥¼ ìš”ì²­í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"ë‘ ê°€ì§€ ì§ˆë¬¸ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì¤˜. í•˜ë‚˜ëŠ” ì£¼ê´€ì‹, í•˜ë‚˜ëŠ” ê°ê´€ì‹ìœ¼ë¡œ, ê·¸ëŸ° ë‹¤ìŒ ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì„ ë³´ë‚´ì¤˜\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "run.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•˜ì§€ë§Œ ì´ì œ Runì˜ `status`ë¥¼ í™•ì¸í•˜ë©´ `requires_action`ì´ í‘œì‹œë©ë‹ˆë‹¤. ì¢€ ë” ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`required_action` í•„ë“œëŠ” ë„êµ¬ê°€ ìš°ë¦¬ì—ê²Œ ì‹¤í–‰í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ Assistantì—ê²Œ ì œì¶œí•˜ë„ë¡ ëŒ€ê¸° ì¤‘ì¸ ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ `display_quiz` í•¨ìˆ˜ì…ë‹ˆë‹¤! ë¨¼ì € `name` ë° `arguments`ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "> **ì°¸ê³ **\n",
    "> ì´ ê²½ìš°ì—ëŠ” í•˜ë‚˜ì˜ ë„êµ¬ í˜¸ì¶œí•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” AssistantëŠ” ì—¬ëŸ¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸°ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tool call\n",
    "tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n",
    "name = tool_call.function.name\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "print(\"Function Name:\", name)\n",
    "print(\"Function Arguments:\")\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ Assistantì—ì„œ ì œê³µí•œ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œë¡œ `display_quiz` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = display_quiz(arguments[\"title\"], arguments[\"questions\"])\n",
    "print(\"Responses:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¢‹ìŠµë‹ˆë‹¤! (ì´ ì‘ë‹µë“¤ì€ ì´ì „ì— ëª¨ì˜ë¡œ ë§Œë“¤ì—ˆë˜ ê²ƒì…ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” ì´ í•¨ìˆ˜ í˜¸ì¶œì—ì„œ ì…ë ¥ì„ ë‹¤ì‹œ ë°›ì•„ì˜¬ ê²ƒì…ë‹ˆë‹¤.)\n",
    "\n",
    "ì´ì œ ì‘ë‹µì„ ì–»ì—ˆìœ¼ë¯€ë¡œ, Assistantì—ê²Œ ë‹¤ì‹œ ì œì¶œí•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ì „ì— ë¶„ì„í•œ `tool_call`ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” `tool_call` IDê°€ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì‘ë‹µë“¤ì˜ `list`ë¥¼ `str`ë¡œ ì¸ì½”ë”©í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id,\n",
    "    tool_outputs=[\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"output\": json.dumps(responses),\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë‹¤ì‹œ Runì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ ìˆ˜ ìˆìœ¼ë©°, Threadë¥¼ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ğŸ‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²°ë¡ \n",
    "ê°„ëµí•¨ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë‹¤ë£¨ì§€ ì•Šì€ ëª‡ ê°€ì§€ ì„¹ì…˜ë„ ìˆìœ¼ë¯€ë¡œ ë” ìì„¸íˆ ì‚´í´ë³¼ ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n",
    "\n",
    "- [Annotations](https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages): íŒŒì¼ ì¸ìš©ë¬¸ êµ¬ë¬¸ ë¶„ì„\n",
    "- [Files](https://platform.openai.com/docs/api-reference/assistants/file-object): Thread ë²”ìœ„ vs Assistant ë²”ìœ„\n",
    "- [Parallel Function Calls](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling): í•˜ë‚˜ì˜ ë‹¨ê³„ì—ì„œ ì—¬ëŸ¬ ë„êµ¬ í˜¸ì¶œ\n",
    "- Multi-Assistant Thread Runs: ì—¬ëŸ¬ Assistantì—ì„œ ì˜¨ ë©”ì‹œì§€ê°€ ìˆëŠ” ë‹¨ì¼ Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
